version: '3.8'
services:
  recipe-backend:
    build:
      context: .
      args:
        - OLLAMA_HOST=http://34.173.253.123:11434
    ports:
      - "${PORT:-8080}:8080"
    environment:
      - PORT=8080
      - OLLAMA_HOST=http://34.173.253.123:11434
    volumes:
      - ./ai:/usr/src/app/ai
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 300s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    